# containers & kubernetes

advances in the linux kernel made it possible to share a single kernel and hardware but have everything else (files, processes, etc) seperated

containerization vs. virtualization:
    ![](https://www.redhat.com/cms/managed-files/styles/wysiwyg_full_width/s3/virtualization-vs-containers_transparent.png?itok=q-E2I2-L)

server side applications are composed of many different parts that have to logically fit together as one application to the client side
 * containers give these different parts of a program their own seperate encapsulation in a sandbox that cannot access or speak to the others unless you explicitly tell them to 
 * for example, you could have one container for your web server, one for the database, one for program code, another for scripts that bring it all together
 * then you can give each container a set of parameters to run (needs access to these ports, this much cpu, this much memory, x number GPUs, etc), and then you can easily pass that to the people who are going to run your code (operations, often automated) for deployment

kubernetes - the OS of the containers needed for a given application
 * you can define general policies to define priority and protocols:
    * I need this much priority (e.g. at least 8 cores), and when it goes down here is the protocol, etc.
    * i.e. instead of hard and fast rules you can say here is the general policy about how I want this to be run
    * this is much like how the kernel manages different running processes on an individual computer

strictly speaking a container is a running image
 * a container image is like a zip file, it contains a bundle of different things and is inert until given to a system that can do something with the image
 * when a system runs the image, that is when you tell it was resources it needs, what port numbers, etc.
 * an instantiated container is the equivalent to a running process on linux
    * you can pause it, stop it, start it up again, etc.
    
